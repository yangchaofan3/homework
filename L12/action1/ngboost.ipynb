{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.4190 val_loss=0.0000 scale=1.0000 norm=2.0000\n",
      "[iter 50] loss=0.3427 val_loss=0.0000 scale=1.0000 norm=1.7212\n",
      "[iter 100] loss=0.3005 val_loss=0.0000 scale=1.0000 norm=1.6308\n",
      "[iter 150] loss=0.2782 val_loss=0.0000 scale=1.0000 norm=1.5989\n",
      "[iter 200] loss=0.2683 val_loss=0.0000 scale=1.0000 norm=1.5975\n",
      "[iter 250] loss=0.2606 val_loss=0.0000 scale=1.0000 norm=1.5968\n",
      "[iter 300] loss=0.2531 val_loss=0.0000 scale=1.0000 norm=1.5853\n",
      "[iter 350] loss=0.2493 val_loss=0.0000 scale=0.5000 norm=0.7903\n",
      "[iter 400] loss=0.2464 val_loss=0.0000 scale=1.0000 norm=1.5743\n",
      "[iter 450] loss=0.2439 val_loss=0.0000 scale=0.5000 norm=0.7862\n",
      "[iter 500] loss=0.2421 val_loss=0.0000 scale=0.0312 norm=0.0491\n",
      "[iter 550] loss=0.2408 val_loss=0.0000 scale=1.0000 norm=1.5703\n",
      "[iter 600] loss=0.2405 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 650] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 700] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 750] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 800] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 850] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 900] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 950] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['user_id'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-71ed5b736146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m## 转化为二分类输出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Attrition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Attrition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Attrition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submit_ngb.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1644\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"loc\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1645\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['user_id'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv',index_col=0)\n",
    "test=pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n",
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "\n",
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)\n",
    "\n",
    "import ngboost as ng\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "\n",
    "model = ng.NGBClassifier(n_estimators=1000, \n",
    "                              learning_rate=0.01, \n",
    "                              verbose=True, \n",
    "                              verbose_eval=50\n",
    "                             )\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#predict = model.predict(test)\n",
    "predict = model.predict_proba(test)[:, 1]\n",
    "#print(predict)\n",
    "test['Attrition']=predict\n",
    "## 转化为二分类输出\n",
    "test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test[['user_id','Attrition']].to_csv('submit_ngb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index()[['user_id','Attrition']].to_csv('submit_ngb.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
