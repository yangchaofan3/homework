***Thinking 1 什么是近似最近邻查找，常用的方法有哪些***

> ANN 近似最近邻查找，是指在牺牲可接受范围内的精度的情况下提高检索效率的方法，适用于在高维海量的数据库中查找数据。
>
> 常用方法：
>
> 1.  **LSH** 局部敏感哈希，相邻的数据通过映射后依然保持相邻的关系即局部敏感度。
> 2. **MinHash** 特征矩阵按行进行随机排列后第一个列为1的行的行号组成minhash值。
> 3. **MinHash + LSH** ，在MinHash基础上将Signature向量分成多个band，按是否有相同的band分桶，只要两个Signature被分到同一个桶内即作为候选相似项。
> 4. **SimHash**：两个二进制串中不同位的数量（hamming距离）在0-10之间认为两个signature近似。



***Thinking 2 为什么两个集合的 minhash值相同的概率等于这两个集合的 Jaccard相似度***

> ​	首先，两个集合每行的关系有A：同为1（a），B：一行1一行0 (b)，C：同为0 (c)三种情况。
>
> ​	在计算MinHash值时关注的是任意行变换后Ci和Cj两列第一个1出现的行位置，因此C对MinHash的统计无意义可以去除。同样地，Jaccard统计Ci和Cj的情况时 :
> $$
> \frac{|C_i∩C_j|}{|C_i∪C_j|}
> $$
> ​	Jaccard 公式中同样不统计C，因此也可以去除，于是MinHash中h(Ci)=h(Cj)只剩下了A一种情况，于是：
> $$
> P(h(C_i)=h(C_j)) = \frac{a}{a+b}=\frac{|C_i∩C_j|}{|C_i∪C_j|}
> $$
> ​	因此，Jaccard相似度可以等同于MinHash值相同的概率来表示。



***Thinking 3 SimHash在计算文档相似度的作用是怎样的？***

>    首先，*SimHash* 在对两个文档对比时使用了**Hamming距离**的概念：
>
>    *在两个二进制串中不同位的数量称为两个二进制串的 **Hamming距离***
>
> SimHash步骤：
>
> **Step1** 综合存储成本和数据集大小设置SimHash的二进制串位数；
>
> **Step2** 初始化SimHash全为0；
>
> **Step3**  采用k-shingles提取文本特征word；
>
> **Step4** 使用传统的hash函数计算各个word的hashcode；
>
> **Step5** 对各word的hashcode的每一位，如果该位为1，则simhash相应位的值加它的权重（通常是出现的频率），否则减它的权重；
>
> **Step6** 计算最后得到的32位的SimHash，如果该位大于1，则设为1否则设为0 。 
>
> 最后， Hamming距离在3以内时认为二进制串相似度比较高，对应的两篇文档基本相同。



***Thinking 4 为什么YouTube采用期望观看时间作为评估指标？***

> ​	这与Youtube的实际商业行为有关，对youtube而言在排序阶段值得关注的，不仅局限于用户是否点击，每个视频用户的观看时长同样可以带来商业价值，例如根据时长权重决定是否需要在某个视频中植入广告。此外，CTR指标对于视频搜索具有一定欺骗性，可能更倾向于短视频，所以提出采用期望观看时间作为评估指标。因此正负样本的比值中正样本用观看时长赋予权重，负样本赋予单位权重，它的odds从传统用点击概率表示的
> $$
> odds = \frac{p}{1-p}
> $$
> ​	变成
> $$
> odds = E[T] * \frac{N}{N-k} =  E[T] * \frac{1}{1-p}\approx E[T]
> $$
> ​	由于在实际中一个用户看过的视频远小于整个网站上的视频，因此p接近0，所以近似用用户的期望观看时间作为评估指标。



***Thinking 5 为什么YouTube在排序阶段没有采用经典的 LR（逻辑回归）当作输出层，而是采用了Weighted Logistic Regression？***

> 原理同thinking4 ，这里Weighted Logistic Regression把用户的观看时长作为odds上分子附加的权重，对于分母没有观看的视频只有单位权重1。